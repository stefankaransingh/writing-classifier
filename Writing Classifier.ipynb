{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,LeakyReLU\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mapping.json') as f:\n",
    "    CLASS_MAPPING = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/emnist-balanced-train.csv',header=None)\n",
    "test = pd.read_csv('data/emnist-balanced-test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112800, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18800, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0   45    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1   36    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2   43    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3   15    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#28*28 image\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(0,axis=1)\n",
    "y_train = train[0]\n",
    "X_train = X_train.values.reshape((len(X_train),28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(0,axis=1)\n",
    "y_test = test[0]\n",
    "X_test = X_test.values.reshape((len(X_test),28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f103743acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[6].transpose().reshape(28,28),cmap='gray')\n",
    "print(CLASS_MAPPING[str(y_train[6])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "num_classes = len(pd.unique(train[0]))\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28x28 pixel images\n",
    "img_rows,img_cols = 28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (112800, 28, 28, 1)\n",
      "X_test shape: (18800, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0],1,img_rows,img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0],1,img_rows,img_cols)\n",
    "    input_shape = (1,img_rows,img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0],img_rows,img_cols,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],img_rows,img_cols,1)\n",
    "    input_shape = (img_rows,img_cols,1)  \n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "X_train_tmp = []\n",
    "for x in X_train:\n",
    "    X_train_tmp.append(x.transpose().reshape(28,28,1))\n",
    "X_train= np.array(X_train_tmp)\n",
    "\n",
    "X_test_tmp = []\n",
    "for x in X_test:\n",
    "    X_test_tmp.append(x.transpose().reshape(28,28,1))\n",
    "X_test= np.array(X_test_tmp)\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "\n",
    "print(\"X_train shape: \"+ str(X_train.shape))\n",
    "print(\"X_test shape: \"+ str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_model(num_classes,input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
    "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                  optimizer = keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_v1(num_classes,input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))                  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))           \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(256, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))           \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(256, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))           \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    #model.load_weights(\"model/model_v1_best_weights.h5\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer = keras.optimizers.adam(),\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_vgg16(num_classes,input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), input_shape=input_shape, padding='same',\n",
    "           activation='relu'))  \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    #model.load_weights(\"model/model_vgg16_best_weights.h5\")\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer = keras.optimizers.adam(),\n",
    "                      metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112800 samples, validate on 18800 samples\n",
      "Epoch 1/50\n",
      "112800/112800 [==============================] - 24s 213us/step - loss: 1.7877 - acc: 0.4781 - val_loss: 0.6118 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79888, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 2/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.7358 - acc: 0.7549 - val_loss: 0.4586 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79888 to 0.83947, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 3/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.6005 - acc: 0.7960 - val_loss: 0.4170 - val_acc: 0.8541\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83947 to 0.85410, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 4/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.5384 - acc: 0.8155 - val_loss: 0.3902 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85410 to 0.86378, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 5/50\n",
      "112800/112800 [==============================] - 23s 201us/step - loss: 0.4937 - acc: 0.8293 - val_loss: 0.3715 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86378 to 0.86729, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 6/50\n",
      "112800/112800 [==============================] - 23s 201us/step - loss: 0.4697 - acc: 0.8363 - val_loss: 0.3548 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86729 to 0.87191, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 7/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.4501 - acc: 0.8439 - val_loss: 0.3419 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.87191 to 0.87670, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 8/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.4380 - acc: 0.8476 - val_loss: 0.3437 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/50\n",
      "112800/112800 [==============================] - 23s 201us/step - loss: 0.4216 - acc: 0.8521 - val_loss: 0.3353 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87670 to 0.87814, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 10/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.4095 - acc: 0.8542 - val_loss: 0.3324 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.87814 to 0.88005, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 11/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.4022 - acc: 0.8574 - val_loss: 0.3298 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.88005 to 0.88085, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 12/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3943 - acc: 0.8595 - val_loss: 0.3206 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.88085 to 0.88346, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 13/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3878 - acc: 0.8618 - val_loss: 0.3243 - val_acc: 0.8811\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3824 - acc: 0.8629 - val_loss: 0.3202 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3769 - acc: 0.8636 - val_loss: 0.3143 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.88346 to 0.88559, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 16/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3680 - acc: 0.8675 - val_loss: 0.3163 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.88559 to 0.88633, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 17/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3651 - acc: 0.8675 - val_loss: 0.3135 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.88633 to 0.88676, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 18/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3611 - acc: 0.8697 - val_loss: 0.3116 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.88676 to 0.88761, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 19/50\n",
      "112800/112800 [==============================] - 23s 201us/step - loss: 0.3600 - acc: 0.8693 - val_loss: 0.3070 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3525 - acc: 0.8715 - val_loss: 0.3077 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3500 - acc: 0.8735 - val_loss: 0.3089 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.88761 to 0.88782, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 22/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3481 - acc: 0.8729 - val_loss: 0.3077 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.88782 to 0.88809, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 23/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3437 - acc: 0.8742 - val_loss: 0.3025 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.88809 to 0.89005, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 24/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3455 - acc: 0.8747 - val_loss: 0.3025 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3407 - acc: 0.8755 - val_loss: 0.3040 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3352 - acc: 0.8773 - val_loss: 0.3085 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3358 - acc: 0.8768 - val_loss: 0.3044 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3346 - acc: 0.8770 - val_loss: 0.2987 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.89005 to 0.89048, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 29/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3316 - acc: 0.8783 - val_loss: 0.3049 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3312 - acc: 0.8788 - val_loss: 0.3010 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3284 - acc: 0.8783 - val_loss: 0.2971 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.89048 to 0.89324, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 32/50\n",
      "112800/112800 [==============================] - 23s 201us/step - loss: 0.3252 - acc: 0.8803 - val_loss: 0.3004 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3202 - acc: 0.8816 - val_loss: 0.2916 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.89324 to 0.89436, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 34/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3216 - acc: 0.8811 - val_loss: 0.2929 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.89436 to 0.89633, saving model to model/model_v1_best_weights.h5\n",
      "Epoch 35/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3220 - acc: 0.8806 - val_loss: 0.2962 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3187 - acc: 0.8819 - val_loss: 0.2943 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3198 - acc: 0.8826 - val_loss: 0.2936 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3184 - acc: 0.8823 - val_loss: 0.2903 - val_acc: 0.8937\n",
      "\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3179 - acc: 0.8818 - val_loss: 0.2929 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3127 - acc: 0.8835 - val_loss: 0.2883 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3118 - acc: 0.8841 - val_loss: 0.2915 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3133 - acc: 0.8836 - val_loss: 0.2913 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3099 - acc: 0.8844 - val_loss: 0.2983 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/50\n",
      "112800/112800 [==============================] - 23s 199us/step - loss: 0.3102 - acc: 0.8837 - val_loss: 0.2990 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/50\n",
      "112800/112800 [==============================] - 23s 201us/step - loss: 0.3107 - acc: 0.8847 - val_loss: 0.2943 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3084 - acc: 0.8846 - val_loss: 0.2952 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3066 - acc: 0.8861 - val_loss: 0.2973 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3098 - acc: 0.8844 - val_loss: 0.2956 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3077 - acc: 0.8850 - val_loss: 0.2928 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/50\n",
      "112800/112800 [==============================] - 23s 200us/step - loss: 0.3049 - acc: 0.8864 - val_loss: 0.2871 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00050: val_acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f7cd87b00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_v1(num_classes,input_shape)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"model/model_v1_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = model_vgg16(num_classes,input_shape)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"model/model_vgg16_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2871089642605883\n",
      "Test accuracy: 0.8962765957446809\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model/model.json','w') as f:\n",
    "    f.write(model_json)\n",
    "model.save_weights('model/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "#import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initial Shape\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_IV3_LAYERS_TO_FREEZE = 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resize = cv2.resize(X_train[1], (150,150))\n",
    "img = cv2.cvtColor(resize,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    resize = cv2.resize(img, (IMG_HEIGHT,IMG_WIDTH))\n",
    "    rgb_img = cv2.cvtColor(resize,cv2.COLOR_GRAY2RGB)\n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_every_n(a, n):\n",
    "    for i in range(a.shape[0] // n):\n",
    "        yield a[n*i:n*(i+1)]\n",
    "\n",
    "X_train_imgs = []\n",
    "for x_train_tmp in get_every_n(X_train,100):\n",
    "    for tmp_img in x_train_tmp:\n",
    "        X_train_imgs.append(preprocess_img(tmp_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/X_train_imgs_150_150.pkl','w') as f:\n",
    "    pickle.dump(X_train_imgs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "  \"\"\"\n",
    "  Add last layer to the convnet\n",
    "  Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "  Returns:\n",
    "    new keras model with last layer\n",
    "  \"\"\"\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1024, activation='relu')(x) \n",
    "  predictions = Dense(nb_classes, activation='softmax')(x) \n",
    "  model = Model(input=base_model.input, output=predictions)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model):\n",
    "  \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "  model.compile(optimizer='rmsprop',    \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_to_finetune(model):\n",
    "   \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top \n",
    "      layers.\n",
    "   note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in \n",
    "         the inceptionv3 architecture\n",
    "   Args:\n",
    "     model: keras model\n",
    "   \"\"\"\n",
    "   for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "      layer.trainable = False\n",
    "   for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "      layer.trainable = True\n",
    "   model.compile(optimizer=keras.optimizers.SGD(lr=0.0001, momentum=0.9),   \n",
    "                 loss='categorical_crossentropy')\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preprocess_img(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = add_new_last_layer(base_model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_imgs,y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_train_imgs,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =setup_to_finetune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
